# Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review

This is for the survey paper **Self-Supervised Contrastive Learning for Medical Time Series: A Systematic Review** which was published in *Sensors* in 2023. More details will be added later.

[Paper link.](https://www.mdpi.com/1424-8220/23/9/4221)

Authors: Ziyu Liu (ziyu.liu2@student.rmit.edu.au), Azadeh Alavi (azadeh.alavi@rmit.edu.au), Minyi Li (liminyi0709@gmail.com) and Xiang Zhang (xiang.zhang@uncc.edu)

## Summary:   
We carefully reviewed 43 papers in the field of self-supervised contrastive learning for medical time series. Specifically, this paper outlines the pipeline of contrastive learning, including pre-training, fine-tuning, and testing. We provide a comprehensive summary of the various augmentations applied to medical time series data, the architectures of pre-training encoders, the types of fine-tuning classifiers and clusters, and the popular contrastive loss functions. Moreover, we present an overview of the different data types used in medical time series, highlight the medical applications of interest, and provide a comprehensive table of 51 public datasets that have been utilized in this field. In addition, this paper will provide a discussion on the promising future scopes such as providing guidance for effective augmentation design, developing a unified framework for analyzing hierarchical time series, and investigating methods for processing multimodal data. Despite being in its early stages, self-supervised contrastive learning has shown great potential in overcoming the need for expert-created annotations in the research of medical time series.

## This repo includes:  
* the implementation of time series augmentations (xx.ipython) file;  
* an extended summary table of the 34 reviewed papers, including title, author/year, challenges, contributions, scenario/task/findings, datasets, preprocessing/perturbation, model, performance and link to their implementation codes (if publically released). 


### Extended summary table:
| Title  	| Author (Year) 	| Challenge 	| Contribution 	| Scenario/task/findings 	| Datsets 	| Preprocessing/perturbation 	| Model 	| Performance 	| Code 	|
|:---:	|:---:	|:---:	|:---:	|:---:	|:---:	|:---:	|:---:	|:---:	|:---:	|
| First Steps Towards Self-Supervised Pretraining of the 12-Lead ECG 	| Gedon et al. <br>(2022) 	| Discover a supervision signal from the data itself for self-supervised represenation learning 	| 1) Define a self-supervised learning task and pretraining pro- cedure which can learn generalisable features of ECG data, 2) Develop and show that a ResNet based architecture can successfully be used in combination with our learning task.  	| ECG reconstruction and (anomalies)cliassification; <br>Pretraining on the CODE training dataset, <br>Use transfer learning with the ECG benchmarks: PTB-XL and  CPSC dataset; 	| CODE, <br>CPSC 2018, <br>PTB-XL 	|  	| U-ResNet: <br>ResNet + encoder-decoder + channel-wise fully connected layer + U-Net based skip-connections.  <br>Downstream task(classification): encoder (no bottleneck layer, no U-Net skip connections) + linear classifier  	| AUC：<br>CPSC: <br>+PT: 0.954; <br><br>PTB-XL:<br>+PT: 0.919 	| - 	|
| Self-supervised representation learning from 12-lead ECG data 	| Mehari et al. (2022) 	| Label scarcity in ECG data 	| 1. Comprehensive assessment of self-supervised representation learning for 12-lead ECG data to foster measurable progress.<br>2. Compare instance-based self-supervised methods and contrastive forecasting methods.<br>3. Modify the CPC architecture and training procedure for performance improvements.<br>4. Evaluate downstream classifiers finetued from self-supervised models to training from scratch. 	| Assessment of self-supervised representation learning from clinical 12-lead ECG data:<br>-data efficiency (downstream performance by number of folds used in finetuning);<br>-quantitative performance (macro AUC);<br>-robustness (influence of physiological noise on downstream performance) 	| Pretraining:<br>CinC2020,<br>Chapman,<br>Ribeiro<br><br>Evaluation:<br>PTB-XL 	|  	| Modified CPC (4FC+2LSTM+2FC);<br><br>Compared with:<br>Supervised (4FC+2LSTM+2FC)<br>Supervised (xresnet1d50)<br>SimCLR(RRC, TO)(xresnet1d50)<br>SimCLR physio(xresnet1d50)<br>BYOL(RRC,TO)(xresnet1d50)<br>BYOL physio. (xresnet1d50)<br><br>*physiological noise, (RRC, TO) are transformations 	| Macro AUC(on PTB-XL):<br><br>Modified CPC:<br>Linear:0.9272<br>finetuned:0.9418<br><br> 	| https://github.com/hhi-aml/ecg-selfsupervised 	|
| Semi-Supervised Contrastive Learning for Generalizable Motor Imagery EEG Classification 	| Han et al.<br>(2021) 	| Label scarcity in ECG data 	| 1. A semi-supervised framework with a combination of self-supervised contrastive learning and adversarial training.<br>2. Semi-supervised learning structure with contrastive learning for unlabelled data.<br>3. Adversarial training to disentangle the subject/session-specific information from the desired MI information in the latent representation. 	|  	| BCIC IV 2a MI-EEG dataset from the MOABB library 	| Filtered between 4Hz and 40Hz, converted it into microvolt. all 22 channels of the EEG and the entire 4 seconds of the trial windows. The EEG windows were then resampled from 250Hz to 128Hz resulting in a length of 512 sample points for each window and processed through channel-wise z-score normalisation. 	| Augmentation-based contrastive loss + task classification loss + domain discriminator loss <br>EEGNet, DeepConvNet as the encoder backbone 	| Semi-DeepConvNet:<br>10%: 67.6<br>20%: 74.3<br>50%: 77.4<br>100%: 79.4 	| - 	|
| Self-Supervised Representation Learning from Electroencephalography Signals 	| Banville et al.<br>(2019) 	| Supervised models are limited by the cost - and<br>sometimes the impracticality - of data collection and labeling 	| 1. Propose self-supervised strategies to learn end-to-end features from unlabeled time series such as EEG. <br>2. Two temporal contrastive learning tasks refer to as “relative positioning” and “temporal shuffling”. <br>3. On a downstream sleep staging task, outperform traditional unsupervised and purely supervised approaches, specifically in low-data regimes. 	| Demonstrate that contrastive learning tasks based on predicting whether time windows are close in time can be used to learn EEG features that capture multiple components of the structure underlying the data<br>(time windows close in time should share the same label) 	| Sleep EDF,<br>MASS session3 	| Both:raw EEG ->4th-order FIR lowpass filter (20-Hz cutoff frequency and Hamming window)<br>MASS: downsampled to 128Hz, extracted non-overlapping 30-s windows, windows were normalized (to focus on Fz,Cz and Oz channels.) 	| Pre-tain:sample pairs of time windows (RP: x_t,x_t'; TS: triplets: x_t, x_t', x_t'') + feature extractor (CNN) + contrastive module aggregate the feature representation of each window (elementwise absolute difference)<br><br>Finetuning: feature extractor (CNN) + linear context discriminative model 	| Average per-class recall:<br>RP: 76.66<br>TS: 75.9<br><br>EEG features: 79.43<br>Fully supervised: 72.51 	| - 	|
| Anomaly Detection on Electroencephalography with Self-supervised Learning 	| Xu et al.<br>(2020) 	| 1. Hand crafted features could omit potentially discriminative feature;<br>2. Labeling of EEG signals of the state of epilepitc seizures have become bottleneck in applying deep learning;<br>3. Individual differences of patients with epilepsy and certain abnormal brain activities share with other brain dieases. generalize issue 	| 1. A new self-supervised learning method based on only normal EEG data is proposed particularly for detection of any abnormal signal in EEG data.<br>2. A simple and effective method is proposed to generate the self-labeled data for self-supervised learning, in which different labels correspond to different scaling transformations on EEG data.<br>3. Performs significantly better than existing wellknown anomaly detection approaches, and is robust to varying model structures and hyperparameters settings. 	| Higher-frequenct signals in an abnormal EEG data would probably mislead the classifier to predict an incorrect scaling transformation. 	| UPenn and Mayo Clinic's seizure detection challenge dataset 	| Generation of self-labeled EEG data:<br><br>Each sequence of EEG data matrix X_i -> K scalling transformations -> a longer sequence s_k *d (number of values in the original sequence) -> for each scale s_k, all the formed new sequences are collected to form a new scaled EEG data T_k(X_i) 	| CNN classifier for prediction of scaling transformations:<br>Input: self-labeled dataset {(T_k(X_i), k)};<br>Output: K values, each representing the probability of one scaling transformation.<br>Cross entropy -> classifier output, ground truth scaling transformation (one-hot vector)<br><br>Anomaly detection:<br>Trained CNN<br>difference (g) between predicted scalings (T_k) and ground truth scaling (y_k) -> the degree of abnomality for new EEG 	| AUC:<br>Ours(ResNet34): 0.941<br><br>Ablition study on kernel shapes(this paper proposed 3*3 compared to 1*3):<br>BackBone:<br>ResNet34: 0.943<br>VGG19: 0.960  	| - 	|
| Contrastive Representation Learning for Electroencephalogram Classification 	| Mohsenvand et al.<br>(2020) 	| Hand-crafted feature; deep learning in supervised manner restricts the use of learned features to specific task; labeling EEG is cumbersome and requires years of medical training and experimental design; labeled EEG data is limited and existing dataset are small; existing dataset use incompatible EEG setups (different number of channels, sampling rates, types of sensors, etc.) hard to fuse to larger dataset for unsupervised learning. 	| 1. Combine multiple EEG datasets,<br>2. Use the uderlying physics of EEG signals to multiply the number of samples (quadratic increase), <br>3. Learn representations in a self-supervised manner via contrastive learning without requiring labels. 	| 1. Emotion recognition.<br>2. Normal/abnormal classification.<br>3. Sleep-stage scoring. 	| 1. SEED dataset (ER)<br>2. TUH dataset (NAC)<br>3. SleepEDF(SSS) 	| Channel recombination: By subtracting two channels, one obtains a new channel that represents the voltage difference between the two sensors, resulting in another physiologically valid channel.<br>Preprocessing: resampled all datasets to 200Hz and applied a fifth-order band-pass Butterworth filter (0.3-80 Hz).  removed the channels that involved voltages higher than 500 μVs as they normally represent artifacts. To train the encoder, cut the channels into chunks of 20 seconds 	| Channel augmenter: each channel, randomly applies two of the augmentations resulting in a positive pair.<br>Channel encoder: recurrent encoder, convolutional encoder.<br>Projector: downsampling and bidirectional LSTM units--each direction output concatenated and fed into dense layerswith a ReLU activation in between.<br>Contrastive loss: identical to the NT-Xent(normalilzed temperature-scaled coress entropy) loss.<br>Downstream tasks: Classifier: discard the projector and use a classifier almost identical to the projector:  	| fine-tuned SeqCLR:<br>1. (C) 50%: 85.21<br><br>2. (C) 50%: 87.21<br><br>3. (R) 50%: 83.72 	| - 	|
| Forecasting adverse surgical events using self-supervised transfer learning for physiological signals 	| Chen et al.<br>(2021) 	| 1. Availability of training data, lack sufficient data or computational resources.<br>2. Patient privacy considerations mean that large public EHR datasets are unlikely, leaving many institutions wiht insufficient resources to train performant models on their own. 	| Improves predictive accuracy by leveraging deep learning to embed physiological signals. using LSTMs, embeds physiological signals prior to forecasting adverse events with a downstream model.<br>Shares models rather than data to address data insufficiency and improves over alternative methods. By transferring performamt models as has been done in medical images and clinical text, scientists can collaborate to improve accuracy of predictive model without exposing patient data.   	| Utilize fifteen physiological signal variables and six static variable inputs to forecast six possible outcomes: hypoxemia, hypocapnia, hypotension, hypertension,<br>phenylephrine administration, and epinephrine administration. 	| Two OR datasets (private, may be available upon request)<br><br>ICU dataset (MIMIC dataset) 	|  	| LSTM for representation learning, followed by fully connected layer as downstream predictor. Use observations in previous 1 hour to predict next 5 mins.  	| - 	| https://github.com/suinleelab/PHASE 	|
| T-DPSOM: An Interpretable Clustering Method for Unsupervised Learning of Patient Health States 	| Manduchi et al.<br>(2021) 	| Traditional clustering methods have poor performance on high-dimensionality dataset -> dimensionality reduction and deature transformation to obtain low-dimentional representation of the raw data (easier to cluster) -> cluster feature lie in a latent space, can not be easily visualized or interpreted or investigating the relationship between clusters. Self-Organizing Map is a clustering method that provides such an interpretable representation. 	| 1. A deep clustering architecture conbines a VAE with a novel  SOM-based clustering objective.<br>2. An extension of this architecture to time series, improving clustering performance, enabling temporal forecasting.<br>3. Showing superior performance on static image data and medical time series (ICU).<br>4. Cluster patientis into different sub-phenotypes and gain better understanding of disease patterns and individual patient health states. 	| A useful tool to understand and track patient health states in the ICU. 	| MNIST,<br>Fashion-MNIST,<br>eICU dataset 	| For eICU: use vital sign(d=14) and lab measurements(d=84) resampled to a 1-hour based grid using forward filling with population statistics from training set if no measurements were available prior to the time point. <br>From ICU stays: 3 days<include< 30days, or has gap in continuous vital sign monitoring. Overall data dimension d=98.<br>The last 72 hours of multivariate time series were used for the experiments. As labels, use a variant of the current dynamic APACHE. 	| A data point 𝑥𝑖 is mapped to a continuous embedding 𝑧𝑖 using a VAE. In T-DPSOM, the embeddings 𝑧𝑖,𝑡 for 𝑡 = 1,...,𝑇 are connected by an LSTM, which predicts the embedding 𝑧𝑡 +1 of the next time step.           	| clustering NMI:<br>0.1115+-0.0006 	| https://github.com/ratschlab/dpsom 	|
| CLOCS: Contrastive Learning of Cardiac Signals Across Space, Time, and Patients 	| Kiyasseh et al.<br>(2021) 	|  	| 1. Propose a family of patient-specific contrastive learning methods, that exploit both temporal and spatial information present in ECG signals.<br>2. Outperforms state-of-the-art methods, BYOL and SimCLR, when performing a linear evaluation of, and fine-tuning on, downstream tasks involving cardiac arrhythmia classification. 	| Downsteam task: cardiac arrhythmia classification<br><br>Human physiology where abrupt changes in cardiac function (on the order of seconds) are unlikely to occur.<br>multiple leads (collected at the same time) will reflect the same underlying cardiac function. 	| PhysioNet 2020,<br>Chapman,<br>PhysioNet 2017,<br>Cardiology 	| Gaussian, Flip, SpecAugment 	| Pre-train: Contrastive Multi-segment Coding; Contrastive Multi-lead Coding, Contrastive Multi-segment Multi-lead Coding<br>Downstream task: 1)Linear Evaluation of representation (pre-train, fine-tune same dataset); 2)Transfer capabilities of representations (pre-train, fine-tune different dataset) 	| AUC:<br>1)CMSC(Chapman): 0.896+-0.005<br>CMSC(PhysioNet2020): 0.715+-0.033<br>2)CMSC(Chapman+PhysioNet2020): 0.83+-0.002<br>CMSC(PhysioNet2020+Chapman): 0.932+-0.008<br>CMSMLC(PhysioNet2020+PhysioNet2017):0.774+-0.012  	| https://github.com/danikiyasseh/CLOCS 	|
| Segment Origin Prediction: A Self-supervised Learning Method for Electrocardiogram Arrhythmia Classification 	| Luo et al. (2021) 	| 1. Lack of well-annotated labels,<br>2. Compared to random weight initlization, pre-trained model weights can help to allivate overfitting 	| Develop a new augmentation: reorganization.  	| Single-lead ECG classification: heart arrithmia detection 	| PhysioNet2017, <br>CPSC2018 	| Discrete wavelet transform (DWT) for denoising 	| Segment origin prediction.  <br>a framework, used 6 different methods as encoder structure. <br>The innonvation is a new augmentation (reorganization). Take two ECG segments/peaks from a pool of segments; if the two taken segments are from the same recording, assign it psudo label 1; otherwise assign psudo label 0. A classifier for psudo label prediction serves as supervision signal for pretraining.  	| PhysioNet2017 for pretrain; CPSC2018 for fine-tuning/test. F1 score: 0.875 	| - 	|
| Learning Unsupervised Representations for ICU Timeseries 	| Weatherhead et al.<br>(2022) 	| 1. Lack of labels in ICU time series<br>2. Allivate the effect of severe data imbalance 	| 1. Improved TNC model by using autocorrelation encoding based neighborhood defining.<br>2. Overcame the negative sampling bias, i.e., the selected negative sample (far away from target sample) could have the same label with the target sample 	| ICU scenarios: mortality, diagnostic groups, circulatory failure, cardiopulmonary arrest 	| HiRID dataset (public), High-frequency ICU (private) 	|  	| Based on TNC: neighboring samples are regarded as positive, otherwise negative. The neighborhood is calculated/defined by autocorrelation encoding (based on Pearson correlation) 	| F1 score: 0.59 in HiRID mortality; 0.61 in diagnostic group, 0.56 in circulatory failure, 0.77 in cardiopulmonary arrest 	| - 	|
| CROCS: Clustering and Retrieval of Cardiac Signals Based on Patient Disease Class, Sex, and Age 	| Kiyasseh et al.<br>(2021) 	| Given a large, unlabelled clinical database, <br>1. How do we extract attribute information from such unlabelled instances?  <br>2. How do we reliably search for and retrieve relevant instances? 	| 1. A supervised contrastive learning framework, attract representations of cardiac signals associated with a unique set of patient attributes to embeddings, entitled clinical prototypes. 2. Outperforms DTC, in the clustering setting and retrieves relevant cardiac signals from a large database. At the same time, clinical prototypes adopt a semantically meaningful arrangement and thus confer a high degree of interpretability. 	| Clinical representation learning and clustering(setting 1),<br>Clinical information retrieval(setting 2) 	| Chapman,<br>PTB-XL 	| Chapman: cardiac arrhythmia labels-> group into 4 major classes<br>PTB-XL: disease label -> gourp into 5 major classes.<br>Each dataset contains patient sex and age information and is split, at the patient level, into training, validation, and test sets. Each time-series recording is split into non-overlapping segments of 2500 samples (≈ 5s in duration), as this is common for in-hospital recordings. 	| Supervised clustering.<br>"We modified the ResNet18 architecture whereby the number of blocks per layer was reduced from two to one, effectively reducing the number of parameters by a factor of two."3 layers of CNN, each layer includes Conv 1D 7 x 1 x 4,<br>BatchNorm, ReLU, MaxPool(2), Dropout(0.1).<br>The 4th layer is Linear with ReLU. 	| Clustering:<br>1. cardiac arrhythmia class attribute:<br>CP CROCS(Chapman) acc: 90.3:<br>CP CROCS(PTB-XL) acc: 76.0<br>2. Sex and age attributes:<br>chapam: CP CROCS(sex):57.4; (age): 38.0<br>PTB-XL: CP CROCS(sex): 73.5; TP CROCS(age): 39.4<br>Retrieval:<br>check paper 	| - 	|
| Self-Supervised Graph Neural Networks for Improved Electroencephalographic Seizure Analysis 	| Tang et al.<br>(2022) 	| 1. Representing non-Euclidean data structure in EEGs, <br>2. Accurately classifying rare seizure types, <br>3. Lacking a quantitative interpretability approach to measure model ability to localize seizures. 	| 1. Representing the spatiotemporal dependencies in EEGs using a GNN and proposing two EEG graph structures that capture the electrode geometry or dynamic brain connectivity, <br>2. Proposing a self-supervised pre-training method that predicts preprocessed signals for the next time period to further improve model performance, particularly on rare seizure types, <br>3. Proposing a quantitative model interpretability approach to assess a model’s ability to localize seizures within EEGs.  	| Seizure detection and classification<br>use self-supervised pre-training: predict future 12 seconds to learn task-agnostic representations and improve downstream task (detection amd classifican) performance  	| Temple University Hospital EEG Seizure Corpus (TUSZ),<br>a in-house dataset 	| Transform raw EEG to the frequency domain, obtian the log-amplitudes of the the fast Fourier transform of raw EEG signals.<br>Detection and self-supervised pre-training: use both seizure and non-seizure EEGs, obtain the 12-s(60-s)EEG clips sing non-overlapping 12-s(60-s) sliding windows.<br>Classification: use only seizure EEGs and obtain one 12-s(60-s) EEG clips from each seizure event(such that each EEG clip had exactly one seizure type), use a refined seizure classification scheme: four zeizure classes in total. 	| Augmentation: a) randomly scaling, b) randomly reflecting the signals along the scalp midline.<br>Distance graph:  represent the natural geometry of EEG electrodes, compute edge weight by applying a thresholded Gaussian kernel to the pairwise Euclidean distance between electrodes.<br>Correlation graph: capture dynamic brain connectivity, define the edge weight as the absolute value of the normalized cross-correlation between the preprocessed signals in electrodes.<br>Encoder: DCGRU-Diffusion Convolutional Gated Recurrent Units 	| With pre-training:<br>Seizure detection AUROC:<br>Dist-DCRNN(12s): 0.866+-0.016<br>Dist-DCRNN(60s): 0.875+-0.016<br><br>Serizure classification weighted F1-score:<br>12s:<br>Dist-DCRNN: 0.746+-0.024<br>60s:<br>Corr-DCRNN: 0.749+-0.017<br>Dist-DCRNN: 0.749+-0.028 	| Yes<br>https://github.com/tsy935/eeg-gnn-ssl 	|
| Domain-guided Self-supervision of EEG Data Improves Downstream Classification Performance and Generalizability 	| Wagh et al.<br>(2021) 	| Can we make encoders learn desirable physiological or pathological features through bespoke pretext tasks?  	| 1. Propose SSL tasks for EEG based on the spatial similarity of brain activity, underlying behavioral states, and age-related differences; 2. Present evidence that an encoder pretrained using the proposed SSL tasks shows strong predictive performance on multiple downstream classifications; 3. Using two large EEG datasets, show encoder generalizes well to multiple EEG datasets during downstream evaluations. 	| Downstream tasks:<br>EEG grade(normal, abnormal), eye state(eye open, eyes closed), age(young, old), and gender(male, female) classification 	| TUH EEG Abnormal Corpus(TUAB) (extracted the age and gender of recorded subjects, assumed here as non-expert labels, from text reports accompanying the EEGs),<br>MPI LEMON 	| Pre-text task:<br>Hemipheric symmetry(HS): aug1-randomly flipping, aug2-add Gaussian noise;<br>Behavioral state estimation(BSE): DBR-delta-beta power ratio(proxy measure of the subjects's behavioral state);<br>Age contrastive(AC): a triplet training tuple constructed from 3 EEG epochs:(X,X+,X_), similarity measured by Euclidean distance, triplet loss. (same age group labeled similar). 	| Pre-training:<br>represented the EEG epochs by 2D images (topographical map of the spectral power in a brain rhythm band)<br>->Resnet-18 backbone(feature extractor) ->three linear layers(projector) -> three SSL pre-text task layer-> multi-task loss(total loss from three tasks)<br>Fine-tuning:<br>(Resnet-18 backbone -> linear layer) x 4 (four dowmstream tasks) 	| Binary classification (AUC):<br>TUH:<br>BSE only(eeg grade): 0.918(3e-4)<br>LEMON:<br>BSE-AC(Age): 0.987(1e-3)<br>HS-BSE-AC(Gender): 0.803(8e-3)<br>* ‘relative positioning’ (RP) pretext task are listed in baseline as the ShallowNet model; RP performs better at age and gender prediction on TUH, and on eye state prediction on LEMON. 	| https://github.com/neerajwagh/eeg-self-supervision 	|
| CLECG: A Novel Contrastive Learning Framework for Electrocardiogram Arrhythmia Classification 	| Chen et al, (2021) 	| Lack of annontations in ECG 	| Contrastive learning framework for ECG pre-training 	| Heart arrhythmia detection 	| PTB-XL for traning, ICBEB2018 and PhysioNet 2017 for fine-tuning 	|  	| Augmentation: Daubechies wavelet transform, and random crop (randomly drop partial values). <br><br>Encoder: xresnet101 backbone +MLP projection head 	| F1 0.788 for PhysioNet2017; 0.942 (F1) on ICBEB2018 	| - 	|
| Self-Supervised Learning with Electrocardiogram Delineation for Arrhythmia Detection 	| Lee et al., (2021) 	| Lack of annontations in ECG 	| Propose a mixed schematic diagram by combining self-supervised representations and manually extracted features for ECG delineation 	| Heart arrhythmia detection 	| CPSC, PT-BXL, Shaoxing-Chapman 	|  	| m-ResNet architecture 	| F1:<br>With 10% labels, 69.18 for CPSC, 66.86 for PTB, 81.49 for Shaoxing 	| - 	|
| Towards Parkinson’s Disease Prognosis Using Self-Supervised Learning and Anomaly Detection 	| Jiang et al.<br>(2021) 	| 1. No enough label to detect PK<br>2. PD is chronic disease that last for long time, the positive samples could be very diverse as they are collected span a long period.  	| Form PD detection as a task of anomaly detection. Use contrastive learning to learn representations unsupervisely, then detect PD with anomaly detection model 	| PD detection 	| mPower data 	| Sensory signals are downsampled to 10% of original sampling rate, to reduce high frequency noise 	| CPC for SSL pre-training, One-Class Deep SVDD for anomaly detection.  	| AUC: 67.3 	| - 	|
| Detection of maternal and fetal<br>stress from the electrocardiogram<br>with self supervised representation<br>learning 	| Sarkar et al.<br>(2021) 	| DL's utility in non-invasive biometric monitoring during pregnancy not well studied 	| 1. Validated the chronic stress exposure by psychological inventory, maternal hair cortisol and FSI(Fetal Stress Index). 2. Tested two variants of SSL architecture, one trained on the generic ECG features for emotional recognition obtained from public datasets and another transfer learned on private data. 3. Provides a novel source of physiological insights into complex multi‐modal relationships between different regulatory systems exposed to chronic stress.  	| Detection of maternal and fetal stress from abdominal ECG (the aECG was deconvoluted into fetal and maternal ECG-fECG, mECG)  	| AMIGOS,<br>DREAMER,<br>WESAD,<br>SWELL,<br>FELICITy (private) 	| Performed minimal pre-processing on the raw data. re-sampled ECG signals to a sampling frequency to 256 Hz, segmentation into 10-s windows. To remove the noisy parts of aECG and mECG data, utilized the SQI values available with the segments, SQI < 0.5 were discarded. resulted in removing approximately 4.1% of total acquired data with a standard deviation of 8.8.(approximately 50 min (46.07 ± 8.74) of ECG data from each participant were used) 	| Transformations: noise addition, scaling, negation, temporal inversion, permutation, time-warping<br>1. Signal transformation recognition network (pre-train)<br>Transformed ECG -> three convolutional blocks, each consists of two 1D convolution layers with ReLU and a max pooling layer -> global max pooling -> several fully connected layers<br>2. Affective recognition network (fine-tune)<br>Raw ECG-> Frozen network ->flatening layer -> several FC layers -> classification task & regression tasks 	| Classification(Detection of stressed mothers):<br>AUROC: <br>FELICITy dataset: (mECG) 0.931<br>Public dataset(transfer learning: public+private dataset): (mECG) 0.982<br><br>Regression(Prediction of biomarkers):<br>Public datasets: (mECG)<br>Cortisol: 0.931; FSI: 0.946; PDQ: 0.961; PSS: 0.943. 	| https://github.com/pritamqu/SSL-ECGv2 	|
| Self-supervised transfer learning of physiological representations from free-living wearable data 	| Spathis et al.<br>(2021) 	| 1. Label scarcity problem in wearable data;<br>2. Multimodal learning approaches rely on the modalities being used as parallel inputs, limiting the scope of the resulting representations. 	| 1. The new pre-training task forecasts ECG-level quality HR in real-time by only utilizing activity signals, <br>2. Leverage the learned representations of this model to predict personalized health-related outcomes through transfer learning with linear classifers.  	| Set HR responses as the supervisory signal for the activity data, predict personalized health-related outcomes 	| The Fenland study<br>(not public, but can request) 	| Heart rate-noise removal, accelerometer data: auto-calibrated to local gravity, non-wear time was inferred and participants with less than 72 hours of wear were removed. Magnitude of acceleration was calculated through the Euclidean Norm Minus One and the high-passed fltered vector magnitude. Both the accelerometry and ECG signals-summarized to a common time resolution of one observation per 15 seconds. encoded the sensor timestamps using cyclical temporal features. 	| Input: X (sensors), M (metadata), y (target HR)<br>Output : E ̃ (user-level embedding), y ̃ (target variable)<br>network:<br>pass X through CNN & GRU layers;<br>pass M through reLU layers;<br>concatenate outputs in E;<br>forecast & backpropagate with joint loss L;<br>use trained network to extract embeddings E;<br>aggregate E to the user-level E ̃ with average pooling;<br>train a linear model to predict target variables y ̃;<br>Downstream: traditional classifier 	| (A/R/T)=acceleration features/resting heart rate/temporal features<br><br>outcome: sex<br>AUC: step2heart(A/R/T): 93.4<br><br>outcome: height<br>AUC: step2heart(A/T): 82.1 	| https://github.com/sdimi/Step2heart 	|
| Supervised and Self-Supervised Pretraining Based Covid-19 Detection Using Acoustic Breathing/Cough/Speech Signals 	| Chen et al.<br>(2022) 	| The amount of COVID-19 audio data in each sub-task (breath/cough/speech) is still limited, the traditional MFCC feature might be not sufficiently representative for classification tasks. 	| 1. A supervised pre-training method, the model use breath, cough and speech to train three different model and obtain an average model (used as an initialization model). (input: MFCC feature)<br>2. A self-supervised pre-training method, use the pre-tained wav2vec2.0 model to extract high-level features, which are input into the diagnosing model to replace the classic MFCC feature.<br>3. Ensemble the scores obtained by the two models 	| COVID-19 detection (binary classification) 	| DiCOVA-ICASSP 2022 challenge dataset 	| The amplitude of the raw waveform is normalized between -1 to 1, cut off silent segments, sound data is downsampled to 16 kHz, forty dimensional MFCC and delta-delta coefficients and extracted with a window of 25 msec audio samples and a hop of 10 msec. use SpecAugment time-frequency mask to augment the data(due to small size of the training data) 	| Model: two bi-directional LSTM layers(encoder) + two linear transformations with a ReLU activation in between(classifier)<br>Supervised pre-train: average model (average three BiLSTM task model) as initialize of classifier.<br>Self-supervised pre-training: wav2vec2.0 model (raw waveform -> a CNN based encoder + a transformer encoder + a quantization model discretizeds the output of feature encoder as targets in the contrastive objective.)<br>Ensemble: train two models, ensemble the scores.  	| AUC: 88.44 on blind test in the fusion track 	| - 	|
| Contrastive Predictive Coding for Anomaly Detection of Fetal Health from the Cardiotocogram 	| de Vries et al.<br>(2022) 	| Low availiability of pathological data along with the high variability in pathologies and a scarcity of available labels 	| 1. Extended the original CPC model by making stochastic, recurrent, and conditioned (upon uterine contractions) predictions, and a custom loss function.<br>2. Based on the detection of out-of-distribution behaviour and deviations from subject-specific behaviour, the proposed model is capable of achieving promising results for identification of suspicious and anomalous FHR events in the CTG 	| Detection of fetal health from CTG<br>* CTG provides a temporal recording of both the Fetal Heart Rate (FHR) and Uterine Contractions (UC) 	| Dutch STAN trial,<br>a healthy dataset 	| Fatal heart rate signals and toco data were pre-processed to yield a constant sampling frequency of 4Hz by means of linear interpolation and subsquently normalized using the mean, and 98th percentile of the healthy dataset.<br>Before normalization, toco signal was filtered by a zero-phase, 4th order Butterworth bandpass-filter with cut-off frequencies at 0.001 and 0.1 Hz.(to eliminate offset and high-frequency noise) 	| Contiditional CPC (Contrastive Predictive Coding) <br>GRU (encoder) + 3 layer MLP (predictor)<br>Use three past windows to predict K=4 <br>Nagetive pair: same signal at different time<br>Training: only use the data of healthy childern. 	| AUC: 0.96 (normal vs anomatous)<br>average correlation coefficient of 0.8 +- 0.13 with respect to expert annotations 	| - 	|
| Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis 	| Ho et al. <br>(2022) 	| Lack of access to the labeled seizure data 	| 1. A self-supervised method for identifying abnormal brian regions and EEG channels without access to the abnormal class data during the training phase.<br>2. Model brain regions and their connectivities using attributed graphs.<br>3. Employing contrastive and generative learning, propose a augmentation approach to creat the postive and negative pairs to form contrastive and generative loss.<br>4. Define a channel-based anomaly score function(linear combination of the contrastive and reconstruction loss)  	| Serizure detection (no access to the seizure data is needed) 	| TUSZ 	| For a given eeg clip, build four types of EEG graphs:<br>Dist-EEG-Graph: use Euclidean distance between electrods, embed the structure of electrode locations in the graph's adjacency matrix.<br>Rand-EEG-Graph: randomly connection of nodes(assume all electroes are connected and eqyally contribute in brain activities, so every edge has the chance of present in the graph)<br>Corr-EEG-Graph:  functional connectivity between electrodes(cross correlation funciton, top-3 neighborhood nodes)<br>DTF-EEG-Graph: directed transfer functiongraph, functional connectivity of the brian regions. 	| Positive and negative pair sampling: 2 positive & 1 negative sub-graphs for every node in every constructed EEG graph(positive:first selected an electrode as target node, target code anonymize in positvie subgraph(replace its feature vector with an all-zero vector); negative:first find the farthest electrode from the target node)<br>Contrastive learning model: pairs-> GNN encoder -> all embeddings -> take avg over rows -> obtian similiarity -> contrastive loss;<br>Generative learning model: (GNN encoder) -> positive embeddings -> GNN decoder(constracting the target node anonymized in the positive subgraphs, using other node features and edges) -> reconstruction loss; 	| Specificity:<br>EEG_t-CGS: 0.989<br>* EEG_t refers to all four graph types are concatenated and fed to the system as the input representing the given EEG clip 	| https://github.com/Armanfard-Lab/EEG-CGS 	|
| A Contrastive Predictive Coding-Based Classification Framework for Healthcare Sensor Data 	| Ren et al.<br>(2022) 	| Annotating data consume a large amount of manpower and resources 	| 1. Designing a contrastive predicting coding(CPC)-based pretext task for medical sensor data classification, redesigning the arrangement of positive sample pairsa dn negative pairs.<br>2. Design a lightweight downstream classification model, further improve the  classification accuracy. 	| 1. Sleep stage classification<br>2. Arrhythmia classification 	| Sleep-EDF,<br>MIT-BIH-SUP 	| Positive sample pair contians 8 different samples belonging to the samle category, and the four left and four right of the negative sample pair belong to the same categories, but the left and right are different categories. 	| Pretext: predict future (GRU)<br>CPC based model<br>Encoder: four blocks, each block: a dense layer, a batch normalizationlayer, an activation layer, a dense layer.<br>Classification: 2 Conv1D layers,  	| Sleep: <br>macro avg ACC: 88.7%<br><br>Arrhythmias:<br>ACC: 97.3% 	| - 	|
| A Contrastive Learning Framework for ECG Anomaly Detection 	| Li et al.<br>(2022) 	| 1. Unbalanced data<br>2. Lack robustness due to inconsistent ECG data representation 	| 1. Effective sequence data augmentation methods are introduced to ECG signal abnormal detection, aims at alleviate category imbalance.<br>2. A new contrastive learning framework that address the challenge of inconsistent data representation during model learning , improve rubustness and accuracy. 	| ECG anomaly detection 	| MIT-BIH arrhythmia dataset,<br>PTB 	| ECG signals were preprocessed and segmented. with each segment corresponding to one heartbeat.<br><br>Augmentation:<br>two methods: BiLSTM-CNN, TimeGAN, (both used in this model) 	| Contrastive learning:<br>Input->BiLSTM&TimeGAN-> Encoder-> Transformer(based on attention mechanism with efficient parallel computing capabilities)-> Non-linear projection head->Maximize similarity<br>Detection:<br>input-> 2 layers of (Conv+Batch Norm)-> max pool -> transformer 	| Arrhythmia: <br>ACC:96.3%<br>PTB diagnostic ECG:<br>ACC: 94.5% 	| - 	|
| Listen to your heart: A self-supervised approach for detecting murmur in heart-beat sounds for the Physionet 2022 challenge 	| Ballas et al.<br>(2022) 	| Lack of labels in ML tranining 	| Propose two augmentation combinations to construct effective positive pairs 	| Murmur classification, and clinical outcome classification 	| PhysioNet 2016 and PhysioNet2022 challenge datasets 	| 5 sec is a window, 50% overlapping<br><br>Augmentation: <br>View1:250Hz high pass filtering<br>View 2: pollute with uniform noise and then upsampling with 0.5 probability 	| CNN as encoder, 3-layer MLP as prediction head.  	| 0.606 in F-score in murmur classification; 0.657 in outcome classification (F1) 	| - 	|
| Weak self-supervised learning for seizure forecasting: a feasibility study 	| Yang et al.<br>(2022) 	| Reduce the burden of manucal labeling 	| Perform a feasibility study on seizure predeciton, which is identified as an ideal test case, as pre-ictal brainwaves are patient-specific, and tailoring models to individual patients is known to improve forecasting performance significantly. * online training 	| Seizure detection and forecasting 	| TUH seizure,<br>EPILEPSIAE dataset,<br>RPAH dataset (pravite) 	| 12s window, ICA and STFT are applied to the EEG before pre-trianed seizure detection.<br>ICA is used for removing EOG artefact. STFT is then applied to the clean EEG with a 250 sample window(1s) and 50% overlap. DC component removed. Same preprocessing used on EEG for prediction. 	| Forecasting model: pre-trained with EPLIEPSIAE, <br>Detection model: pre-trained with TUH, <br>Both model: 3 layers of ConvLSTM, 2 layers of FC(with sigmoid). <br>All three tests, both pseudo-prospectively inference-only real-time tested on the RPAH dataset. 	| Average relative improvement in sensitivity by 14.3% , a reduction in false alarms by 19.6% in early seizure forecasting. 	| https://github.com/NeuroSyd/Weak_learning_for_seizure_forecasting 	|
| Contrastive Heartbeats: Contrastive Learning for Self-Supervised ECG Representation and Phenotyping 	| Wei et al.<br>(2022) 	| High cost of manual labels 	| Propose a contrastive learning approach, to utilize the periodic and meaningful patterns from ECG. 	| Cardiac arrhythmia classification 	| MIT-BIH,<br>Chapman,<br>private large-scale ECG dataset 	| Exclude samples with <48 bpm, within the ten-second measurement;<br>Positive pair: the anchor heartbeat with a positive heartbeat(sample from the same ECG);<br>Negative pair: the anchor heartbeat with a negative heartbeat(sample from other ECG). 	| Heartbeat extract in the full-length ECG by the Hamilton R-peak segmentation algorithm;<br>Backbone model: Causal CNN;<br>Projector: additional fully connected layer(project the featuresof the anchor);<br>Loss: multi-similartiy loss. 	| Linear evaluation on:<br>MIT-BIH: ACC: 89.25;(AUROC=0.9424)<br>Chapman:<br>AUROC: 0.920<br>Private dataset:<br>AUROC: (1AVB) 0.9089<br>Semi-supervised learning:(finetune use paritial labels)<br>MIT-BIH: ACC: (50%) 0.9461 	| - 	|
| Practical cardiac events intelligent diagnostic algorithm for wearable 12-lead ECG via self-supervised learning on large-scale dataset 	| Yang et al.<br>(2022) 	|  	| 1. Collected 658,948 ECG, 164,538 were diagnosed and remaining 493.948 ECGs without diagnosis.<br>2. Train a Siamese network via contrastive learning, transferred the pretained weights to downstream classification.<br>3. Designed four data augmentation operations for 1D digital myltilead ECG signals. 	| Cardiac events diagnostic (55 cardiac events) 	| CPSC 2018,<br>large-scale ECG<br>dataset(can not be open-scourced) 	| 5th order Butterworth high-pass filter, with the lower cutoff frequency of 0.5 Hz.<br>Data augmentation:<br>1. frequency dropout;<br>2. crop resize;<br>3. cycle mask: detect the position of R peak and segment the same position in each heartbeat to zero;<br>4. channel mask. 	| Momentum contrast(MOCO): an encoder and a momentum encoder, and a projection head at the bottom of each encoder. 	| On CPSC 2018: <br>F1 score: 0.839 	| https://github.com/SMU-MedicalVision/ECG-MoCo-Classfication 	|
| As easy as APC: overcoming missing data and class imbalance in time series with self-supervised learning 	| Wever et al.<br>(2021) 	| High levels of missing data and strong class imbalance 	| Demonstrate how Autoregressive Predictive Coding (APC), cna be leveraged to overcome both missing data and class imbalance simultaneouly without strong assumptions. 	| Overcome high missingness and severe class imbalance 	| Synthetic dataset,<br>Physionet challenge 2012,<br>menstrual cycle tracking app Clue 	|  	| Encoder: GRU-D (GRU Decay)<br>APC<br>MaskedMSE 	| Physionet 2012(binary):<br>AUROC: (GRU-APC without class imbalance method): 86.0+-0.5<br><br>Clue dataset(multi class classification):<br>weighted F1: (GRU-APC): 90.7+-0.1 	| https://github.com/fiorella-wever/APC 	|
| DeepClean: Self-Supervised Artefact Rejection for Intensive Care Waveform Data Using Deep Generative Learning 	| Edinburgh et al.<br>(2020) 	| Waveform physiological data in ICU are susceptible to artefacts, removal of artefacts reduced bias and uncertainty in clinical assessment and false positive rate of ICU alarms. 	| 1.A prototype self-supervised artefact detection system using a convolutional variational autoencoder deep neural network that avoids manual annotation, requiring only easily-obtained good data for training.<br>2. Can identify regions of artefact with high accuracy. 	| Artefact detection on ICU waveform physiological data 	| ABP waveform data from single anonymised patient throughout a stay 	| Split the data into 100-second windows, normalising across the whole dataset, sampled uniformly within the selected windowto generate 10-second sample to join the test set (main contain marked(abnormal marked by expert) sample).  	| VAE with CNNs for both encoder and decoder. 	| Accuracy: (mean)<br>VAE: 0.901<br>ROCAUC: 0.973 	| https://github.com/tedinburgh/deepclean 	|
| SOM-CPC: Unsupervised Contrastive Learning with Self-Organizing Maps for Structured Representations of High-Rate Time Series 	| Huijben et al.<br>(2022) 	| High-dimensional real-world data are difficult to interpret.<br>Deep learning aim to identify this manifold, but do not promote structure nor interpretability. 	| 1. SOM-CPC, suitable for learning structured and interpretable 2D representations of high-rate time series by encoding subsequent data windows to a topologically ordered set of quantization vectors.<br>2. Requires far less auxiliary loss function (and associated hyperparameter tuning) 	| Clustering  	| Synthetic dataset,<br>subset 3 of MASS,<br>subset of LibriSpeech dataset 	| For MASS: select three EEG channels(F4, C4, O2), two EOG channels, one chin EMG derivaiton, downsampled to 128Hz, non-overlapping 30-second window. Before downsampling, all derivations filtered with a zero-phase 5th order Butterworth band-pass filter, another zero-phase 5th order Butterworth notch filter. Channels normalized within-patient and per channel, yielding mean substraction, and normalization. 	| SOM-CPC<br>Encoder: CNNs (details in appendix) 	| On sleep dataset:<br>Purity: 0.79<br>NMI: 0.28<br>Cohen's kappa: 0.67<br>l_2 smooth: 1.22+-0.21<br>TE: 0.042 	| - 	|
| Subject-aware contrastive learning for biosignals 	| Cheng et al.<br>(2020) 	| Dataset for biosignals, limited labels and subjects 	| 1. Apply self-supervised learning to biosignals.<br>2. Develop data augumentation techniques for biosignals.<br>3. Integrate subject awareness into the self-supervised learning framework.<br>    1) subject-specific distribution to compute contrastive loss<br>    2) promoting subject invariance through adversarial training 	| EEG decoding, ECG anomaly detection 	| Physionet Motor Imagery,<br>MIT-BIH arrhythmia 	| Raw EEG/ECG data for input.<br>Data transformations for biosignals: temporal cutout, temporal delays, noise, bandstop filtering, signal mixing<br>Spatial locations of electrodes of EEG bad domian-specific transformations:<br>spatical rotation(exceptio), spatial shift(exception), sensor dropout, sensor cutout(exception) 	| Encoder and momentum encoder: 1d ResNet with ELU activation and batch normalization.<br>Project head and momentum project head: 4-layer fully-connected network.<br>Linear classification using logistic regression with weight decay. 	| EEG: ACC<br>Intersubject: 81.6+-0.8(subject-specific, 2 class)<br>Intrasubject: 79.6+-2.3(subject-invariant, 2 class)<br>ECG:<br>Overall: ACC: <br>subject-specific: 93.2+-1.6 	| - 	|
| Sense and learn: Self-supervision for omnipresent sensors 	| Saeed et al. (2021) 	| Non-generalizble representations; Lack of annotations 	| 1. Propose 7 data augmentation schemes<br>2. Design a framework that uses all 7 schemes at the same time to learn generalizable representations 	| EEG, EOG, Heart rate, Skin conductance, accelerometer, gyroscope 	| HHAR, MobiAct, MotionSense, UCI HAR, HAPT, Sleep-EDF, MIT DriveDb, WiFi CSI 	| Blend detection, Fusion magnitude prediction, Feature prediction from masked window, Transformation recognition, Temporal shift prediction, Modality denoising, Odd segment recognition 	| CNN as backbone 	| Kappa scores. HHAR: 0.826, MobiAct: 0.89, MotionSense: 0.907, UCI HAR: 0.888; HAPT: 0.820; Sleep-EDF: 0.702; MIT DriveDb: 0.804; WiFi CSI: 0.798 	| - 	|
| Self-Supervised Learning From Multi-Sensor Data for Sleep Recognition 	| Zhao et al.<br>(2020) 	| 1. Most of sleep recognition methods are limited to single-task recognition, which only involve single-modal sleep data.<br>2. Shortage and imbalance of sleep samples.  	| 1. Study the problem of sleep recognition at three levels: sleep position/sleep stage recognition, insomnia detection.<br>2. Self-supervised sleep recognition model(SSRM) is proposed for multi-sensor sleep recognition. 	| Sleep position/sleep stage recognition, insomnia detection 	| Sleep Bioradiolocation dataset,<br>Pressure Map dataset,<br>PSG dataset 	| Reduce noise and differences, normalized to [0, 1]<br>Pressure map: rotation and frequency-domian feature extraction to generate temporary labels.<br>PSG: preprocess and extract four-dimensional feature and count feature. 	|  	| Prediction probability of CRF as the final accuracy.<br>Bio-radar: 99.03<br>Pressure-e1: 99.55<br>Pressure-e2: 98.92<br>PSG-2class: 95.91<br>PSG-3class: 78.69<br>PSG-4class: 71.01 	| - 	|
| Contrastive Embeddind Learning Method for Respiratory Sound Classification 	| Song et al.<br>(2021) 	| 1. Difficulty of collectionand expensive manual annotation, only limited samples availabe.<br>2. Do not explicitly encourage intra-class compactness and inter-class separability between the learned embeddings. 	| Propose a contrastive embedding learning method, input a contrastive tuple, learn the slight differences among te similar samples, the easily confused samples are more likely to be identified. 	| Respiratory sound classification 	| ICBHI 2017 	| Resample all audio recordings to 16kHz and segment them to respiratory circles according to onsets and offsets. <br>convert the circles to 46-dimentsion log Melspectrograms with the window size of 1024 over a 256-sample hop.<br>repeat the short ones and trim off partially the long ones to ensure the shapes of features are unified. 	| Augmentation: white noise adding, time shifting, time stretching and pitch shifting<br>Encoder: CNN<br>Classifier: linear layer(logistic regression) 	| ACC: 78.73 	| - 	|
| A Semi-Supervised Algorithm for Improving the Consistency of Crowdsourced Datasets: The COVID-19 Case Study on Respiratory Disorder Classification 	| Orlandic et al.<br>(2022) 	| Labelling inconsistencies and label sparsity in the crowdsourced dataset.<br>(1. potentially noisy user label, 2. often contradictory expert labels) 	| 1. Provide an automated approach for increasing the labeling quality of biosignal datasets.<br>2. The subsample of cough audio recordings identified through our SSL approach was made public 	| Respiratory disorder classification/COVID-19 detection 	| COUGHVID dataset 	| A cough classifier was used to remove non-cough recordings (greater than 0.8 is selected), all cough recordings were normalized, applied a 4th order Butterworth lowpass filter(cutoff frequency of 6kHz) to reduce high-frequency noise. <br>Isolate each individual cough event. discard any cough sound candidates shorter than 200ms, include 200ms before and after the cough candidate in each segmented. 	| Supervised(classifier): user model(based on user label), expert 1,2,4 model(based on labels of experts1,2 and 4)<br>SSL model: majority agreement combine the knowledge form both users and experts, to identified a subset of high-confidence samples->used to train on final classifier, the rest were dscarded.<br>User: Linear discrimiant analysis; Expert1,2,4: Logistic regression; SSL: Logistic regression. 	| SSL: Test AUC(Not aggregated):<br>0.763 	| - 	|
| BENDR: Using Transformers and a Contrastive Self-Supervised Learning Task to Learn From Massive Amounts of EEG Data 	| Kostas et al. (2021)  	| Less of generability: task-specific model is required 	| Propose a framework with contrastive pre-tranining, it can be used to different tasks/datasets. It's a transfer learning model essentially. 	|  	| MMI, BCIC, ERN, SSC, P300 	| Augumentation: CPC (predict the future) 	| CNN+Transformer-based CPC 	| MMI: (86.7 in BAC), BCIC:42.6 in Accuracy, ERN 0.65 in AUROC, SSC: 0.72 in BAC; P300: 0.72 in AUROC 	| - 	|
| Unsupervised Anomaly Detection on Temporal Multiway Data 	| Nguyen et al.<br>(2020) 	| Unsupervised temporal models employed thus far typically work on sequences of feature vectors, and much less on temporal multiway data.  	| 1. Investigate the applications of matrix recurrent neural networks for unsupervised anomaly detection for temporal multiway data.<br>2. Two anomaly detection settings (reconstruction and prediction) are examined, and the empirical results on synthetic data, moving digits and ECG readings are reported. 	| Temporal multiway anomaly detection (looks for irregularities over space-time)<br>Use reconstruction loss: an abnormal sequence does not exhibit the regularities, it is hardly compressible, and thus its reconstruction error is expected to be higher than the error in the normal cases.(if a sequence is regular (normal), the history may contain sufficient information to predict several steps ahead) 	| Synthetic data, <br>MNIST,  <br>MIT-BIH Arrhythmia dataset 	| For MIT-BIH: manually pick 38 subjects(have both MLII and V1 channels and no paced beats), For each univariate signal, the raw ECG is detrended by first fitting a 6-order polynomial and then subtracting it from the signal, a 6-order Butterworth bandpass filter with 5Hz and 15Hz range, filtered signals are normalised individually by using Z-score normalisation.  	| Pre-training:<br>(Matrix) LSTM AutoEncoder model:<br>encoder: matLSTM (compresses X into C by reading one matrix at a time）<br>decoder: matLSTM decompresses the memory by predicting one matrix at a time<br>anomaly: reconstruction loss<br>Fine-tuning:<br>(Matrix) LSTM Encoder-Predictor predictive model:<br>anomaly score: mean prediction error 	| matLSTM:<br>(for predicting 5 heartbeats)<br>AUC: 92.5 ± 0.1<br>F1: 72.8 ± 0.2 	| - 	|
| Self-supervised EEG Representation Learning for Automatic Sleep Staging 	| Yang et al.<br>(2021) 	| 1. Unlabeled and noisy data.<br>2. Existing negative sampling strategies often incur sampling bias. 	| 1. Pretext task: address the inherent limitations of negative sampling in the existing self-supervised methods (e.g., MoCo2, SimCLR3) by leveraging global data statistics.<br>2. strengthen our model with an instance-aware world representation for each sample, where closer samples are assigned larger weights. 	| Sleep stage classification 	| SHHS,<br>Sleep EDF,<br>MGH Sleep 	| Subjects are randomly assigned to pretext group, training group and test group with different proportions.<br>Augmentation: Bandpass Filtering, Noising, Channel Flipping, Shifting.<br>ContraWR: Contrast with the World Representation(generate an average representation of the dataset, 𝒛𝒘 as the only contrastive information.)<br>ContraWR+: Contrast with Instance-aware World Representation(weighted average of the world/dataset, where the weight is set higher for closer samples.) 	| Classifier: training a separate logistic regression model (on top of the encoder) on data from the training group (during which the encoder is frozen) and test on new recordings.<br>Projector: 2-layer fully connected network.<br>Encoder:  STFT (Short-Time Fourier Transforms) module, esulting STFT spectrogram passes convolutional layer with batch normalization (CNN-based encoder is built on top of the spectrogram) 	| 5 class classification<br>ContraWR+:<br>Sleep EDF:  86.90 ± 0.2288<br>SHHS: 77.97 ± 0.2693<br>MGH Sleep: 72.03 ± 0.1823<br><br>Baseline: <br>MoCo <br>SimCLR <br>BYOL <br>SimSiam 	| https://github.com/ycq091044/ContraWR 	|
| Self-Supervised Learning for Sleep Stage Classification with Predictive and Discriminative Contrastive Coding 	| Xiao et al.<br>(2021) 	| 1. Labeling work is costly and laborious interms of specialist eperience and manual work.<br>2. ground truth lables annotated by sleep experts can also be contradictory, bad influence on label-relied tasks.<br>3. Extracted representations by supervised models are not generalized. 	| 1. The proposed SleepDPC frameworkis a pioneer to apply SSL on sleep stage classification.<br>2. Proposed two learning principles, Predictive contrastive coding, Discriminative contrastive coding, enable extract high-level semantics(underlying rhythms and patterns) from raw EEG. 	| Sleep stage classification  	| Sleep-EDF,<br>ISRUC 	| Combining PCC and DCC:<br>PCC(predictive contrastive coding): other representation(at different timestep) in the mini-batch are considered as "unrelated"(negative), <br>DCC(discriminative contrastive coding): representations in different segement of a mini-batch are temporally distant, as negative pair.  	| Pre-train:<br>encoder: CNN<br>aggregator: GRU and LSTM<br>predictor: not mentioned<br>Fine-tuning:<br>encoder and aggregator are freezed.<br>classifier: one-layer fully-connected network. 	| SleepDPC(10% labels)<br>SleepEDF:<br>Accuracy:0.701 ± 0.008<br>F1-macro:0.640 ± 0.015<br><br>ISRUC:<br>Accuracy:0.536 ± 0.015<br>F1-macro:0.489 ± 0.018 	| https://github.com/larryshaw0079/SleepDPC 	|
| CoSleep: A Multi-View Representation Learning Framework for Self-Supervised Learning of Sleep Stage Classification 	| Ye et al.<br>(2022) 	| 1. Large-scale labeled datasets are still hard to acquire<br>2. DPC operates discrimination at an instance level(treats each instance as a single class); seasonality of time-searies indicates that distant instances can be semantically close 	| 1. Novel co-training scheme by exploiting complementary information from time and frequency view of physiological signals to mine more pisiive samples. <br>2. Extend the framework with a memory module, implemented by a queue and a moving-averaged encoder, to enlarge the pool of negative candidates 	| Sleep stage classification 	| SleepEDF,<br>ISRUC 	| Use multi-instance infoNCE loss, calculating loss function using multiple positive samples. To select the Top-K positive samples, this work finds the samples that are most similar to anchor sample in both time domain and frequency domain. 	| Pre-training: <br>Two encoders: CNN with residual connections (ResNet); <br>aggregator: GRU/LSTM<br><br>Finetuning:<br>encoder and aggregator are freezed.<br>classifier: one-layer fully-connected network.(10%label) 	| CoSleep:<br>SleepEDF:<br>ACC:0.716 ± 0.043<br>F1:0.558 ± 0.03<br><br>ISRUC:<br>ACC:0.579 ± 0.051<br>F1: 0.501± 0.056 	| https://github.com/larryshaw0079/CoSleep 	|
| A Self-Supervised Learning Based Channel Attention MLP-Mixer Network for Motor Imagery Decoding 	| He et al.<br>(2022) 	| 1. CNN for MI EEG decoding 's performance is generally limited due to the small size sample problem.<br>2. To address 1, EEG trials segment into small slices, usually inevitably losses the longrange dependencies of temporal information. 	| 1. A new EEG slice prediction task as pretext task to capture the long-range information in time domain.<br>2. In the downstream task, a MLP-Mixer is for classification task for signal(rather than image)<br>3. An attention mechanism is integrated into MLP-Mixer to estimated the importance of each EEG channel. 	| Motor Imagery (movement inagination classification) 	| MI-2 Dataset,<br>BCIC-IV-2A Dataset 	| MI-2 dataset: 150 time points sliding window(overlap of 10 points), z-score normalization on each slice.<br>BCI-IV-2A dataset: same 	| Pretext task: 3 adjacent EEG slices -> local encoder(1D CNN) -> concatenation -> LSTM layers -> conv and linear -> predicted EEG slice<br>Downstream task: EEG slice -> Local encoder(with Weights from pretext) -> Channel-attention MPL-Mixer(CAU&TMU) -> Classifier(global average pooling -> Linear layer -> Softmax -> Prediction) 	| MI-2: <br>ACC: 78.5 ± 0.64<br>F1: 78.39 ± 0.67<br><br>BCI-IV-2A:<br>ACC: 79.43 ± 1.73<br>F1: 79.42 ± 1.74 	| - 	|
| Self-supervised Contrastive Learning for EEG-based Sleep Staging 	| Jiang et al.<br>(2021) 	| Data shortage of supervised learning 	| Propose a self supervised contrastive learning for EEG sleep staging classification, measures the feature similarity if transformed signal pairs. 	| EEG-based sleep staging classification 	| Sleep-edf,<br>Sleep-edfx,<br>Dod-O,<br>Dod-H 	| Transformation:<br>Sleep-edf, Sleep-edfx: crop&resize + permutation; crop&resize + crop&resize.<br>all dataset together: crop&resize + time warping; crop&resize + permutation 	| SSL training:<br>input: transformed unlabelled data; encoder: ResNet based; <br>positive pair: homologous pair; negative pairs: others.<br>Fine tuning: classifier: FC layers. 	| Healthy subjects: <br>Acc: 88.16; F1: 81.96<br><br>Healthy and subjects with sleep disorders:<br>Acc: 84.42; F1: 78.95 	| https://github.com/XueJiang16/ssl-torch 	|
| Self-Supervised Contrastive Pre-Training For Time Series via Time-Frequency Consistency 	| Zhang et al.<br>(2022) 	| Lack of data labels 	| Propose the assumption of Time-Frequency Consistency: the infomration taken in time domain and in frequency domain is equivalent. 	| Sleep disorder, Eplipsy detection, Mechanical fault detection, etc. 	|  	| Time domain: shift, jittering, etc. Frequency domain: adding/removing frequency component 	| CNN-based encoder, MLP-based projector 	| - 	| https://github.com/mims-harvard/TFC-pretraining 	|
